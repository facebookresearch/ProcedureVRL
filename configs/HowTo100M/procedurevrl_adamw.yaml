# Copyright (c) Meta Platforms, Inc. and affiliates. All Rights Reserved.
DEV:
  ENABLE: True
  CLIP_VIS_FEAT_PATH: '/fsx/yiwuzhong/data/ht100m/ht100m_videos_clip_proc_16/videos/' # path to pre-computed CLIP features
  MATCH_LANG_EMB: True
  ORDER_PRETRAIN_ENABLED: True
  ORDER_TFM_LAYERS: 4
TRAIN:
  ENABLE: True
  DATASET: howto100m_develop
  BATCH_SIZE: 16 # per machine node
  EVAL_PERIOD: 100 # no evaluation during pretraining
  CHECKPOINT_PERIOD: 3
  AUTO_RESUME: True
  TEXT: '/fsx/yiwuzhong/data/ht100m/MIL-NCE_HowTo100M/howto100m_csv/' # path to video ASR files
  LABEL_EMB: 'data/clip_step_emb_ht100m_vbphrase.pth' # path to language embeddings of step candidates
  TOPK: 5
DATA:
  PATH_TO_DATA_DIR: './data_csv/howto100m_full/' # './data_csv/howto100m_subset/' # path to metadata files
  PATH_PREFIX: '/fsx/yiwuzhong/data/ht100m/ht100m_videos/videos/' # path to video files
  NUM_FRAMES: 8
  SAMPLING_RATE: 32 # determined by DATA.FD
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_CROP_SIZE: 224
  TEST_CROP_SIZE: 224
  INPUT_CHANNEL_NUM: [3]
  FD: 9. # duration of single video clip
  DECODING_BACKEND: 'ffmpeg'
TIMESFORMER:
  ATTENTION_TYPE: 'divided_space_time'
SOLVER:
  BASE_LR: 0.00005
  LR_POLICY: steps_with_relative_lrs
  STEPS: [0, 15, 23]
  LRS: [1, 0.1, 0.01]
  MAX_EPOCH: 25
  MOMENTUM: 0.9
  WEIGHT_DECAY: 1e-4
  OPTIMIZING_METHOD: adamw
MODEL:
  MODEL_NAME: vit_base_patch16_224_develop
  NUM_CLASSES: 9871 # the number of target concepts
  ARCH: vit
  LOSS_FUNC: kldiv
  DROPOUT_RATE: 0.5
  TEXT_MODEL: clip_vit_b_16
  MIN_LEN: 12
TEST:
  ENABLE: False
  DATASET: howto100m_develop
  BATCH_SIZE: 16
  NUM_ENSEMBLE_VIEWS: 4
  NUM_SPATIAL_CROPS: 1
DATA_LOADER:
  NUM_WORKERS: 8
  PIN_MEMORY: True
NUM_GPUS: 8
NUM_SHARDS: 8 # the number of machine nodes
RNG_SEED: 0
OUTPUT_DIR: .
