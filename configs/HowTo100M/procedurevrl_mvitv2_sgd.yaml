# Copyright (c) Meta Platforms, Inc. and affiliates. All Rights Reserved.
DEV:
  ENABLE: True
  CLIP_VIS_FEAT_PATH: '/fsx/yiwuzhong/data/ht100m/ht100m_videos_clip_proc_16/videos/' # path to pre-computed CLIP features
  MATCH_LANG_EMB: True
  ORDER_PRETRAIN_ENABLED: True
  ORDER_TFM_LAYERS: 4
TRAIN:
  ENABLE: True
  DATASET: howto100m_develop
  BATCH_SIZE: 8 # per machine node
  EVAL_PERIOD: 100 # no evaluation during pretraining
  CHECKPOINT_PERIOD: 3
  AUTO_RESUME: True
  TEXT: '/fsx/yiwuzhong/data/ht100m/MIL-NCE_HowTo100M/howto100m_csv/' # path to video ASR files
  LABEL_EMB: 'data/clip_step_emb_ht100m_vbphrase.pth' # path to language embeddings of step candidates
  TOPK: 5
DATA:
  PATH_TO_DATA_DIR: './data_csv/howto100m_full/' # './data_csv/howto100m_subset/' # path to metadata files
  PATH_PREFIX: '/fsx/yiwuzhong/data/ht100m/ht100m_videos/videos/' # path to video files
  NUM_FRAMES: 16
  SAMPLING_RATE: 6 # determined by DATA.FD
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_CROP_SIZE: 224
  TEST_CROP_SIZE: 224
  INPUT_CHANNEL_NUM: [3]
  FD: 3. # duration of single video clip
  DECODING_BACKEND: 'ffmpeg'
TIMESFORMER:
  PRETRAINED_MODEL: './exps/MViTv2_S_in1k_converted.pyth'
MVIT:
  ZERO_DECAY_POS_CLS: False
  USE_ABS_POS: False
  REL_POS_SPATIAL: True
  REL_POS_TEMPORAL: True
  DEPTH: 16
  NUM_HEADS: 1
  EMBED_DIM: 96
  PATCH_KERNEL: (3, 7, 7)
  PATCH_STRIDE: (2, 4, 4)
  PATCH_PADDING: (1, 3, 3)
  MLP_RATIO: 4.0
  QKV_BIAS: True
  DROPPATH_RATE: 0.0 # 0.2
  NORM: "layernorm"
  MODE: "conv"
  CLS_EMBED_ON: True
  DIM_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  HEAD_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[0, 1, 1, 1], [1, 1, 2, 2], [2, 1, 1, 1], [3, 1, 2, 2], [4, 1, 1, 1], [5, 1, 1, 1], [6, 1, 1, 1], [7, 1, 1, 1], [8, 1, 1, 1], [9, 1, 1, 1], [10, 1, 1, 1], [11, 1, 1, 1], [12, 1, 1, 1], [13, 1, 1, 1], [14, 1, 2, 2], [15, 1, 1, 1]]
  DROPOUT_RATE: 0.0
  DIM_MUL_IN_ATT: True
  RESIDUAL_POOLING: True
SOLVER:
  BASE_LR: 0.005
  LR_POLICY: steps_with_relative_lrs
  STEPS: [0, 2, 4]
  LRS: [1, 0.1, 0.01]
  MAX_EPOCH: 5
  MOMENTUM: 0.9
  WEIGHT_DECAY: 1e-4
  OPTIMIZING_METHOD: sgd
MODEL:
  MODEL_NAME: MViT
  NUM_CLASSES: 9871 # the number of target concepts
  ARCH: mvit
  LOSS_FUNC: kldiv
  DROPOUT_RATE: 0.5
  ACT_CHECKPOINT: False # True # following mvit code
  TEXT_MODEL: clip_vit_b_16
  MIN_LEN: 12
TEST:
  ENABLE: False
  DATASET: howto100m_develop
  BATCH_SIZE: 16
  NUM_ENSEMBLE_VIEWS: 4
  NUM_SPATIAL_CROPS: 1
DATA_LOADER:
  NUM_WORKERS: 8
  PIN_MEMORY: True
NUM_GPUS: 8
NUM_SHARDS: 8 # the number of machine nodes
RNG_SEED: 0
OUTPUT_DIR: .
